defaults:
  - default_dataset.yaml
  - _self_

# Strategy A: LoRA on Depth Head Only (Fastest, Recommended Starting Point)
# Focuses on adapting the depth prediction head for building-focused reconstruction
exp_name: lora_kitti360_strategy_a_r16

# LoRA Configuration
lora:
  enabled: True
  rank: 16                  # LoRA rank (start with 16)
  alpha: 32                 # LoRA alpha (alpha/rank = 2.0 scaling)
  dropout: 0.1              # LoRA dropout for regularization
  # Target only Depth Head modules
  target_modules:
    - "depth_head.projects.*"          # Conv layers in DPT projects
    - "depth_head.scratch.*"           # Scratch/fusion blocks
    - "depth_head.scratch.refinenet*.resConfUnit*.conv*"  # Residual conv units

img_size: 518
num_workers: 16
seed_value: 42
accum_steps: 1             # No gradient accumulation for 32GB VRAM
patch_size: 14
val_epoch_freq: 2          # Validate every 2 epochs
max_img_per_gpu: 4         # Conservative for 32GB with high-res images

# Batch size is max_img_per_gpu / sequence_length_effective
# KITTI-360 uses fixed sequence length of 8
limit_train_batches: 2000  # Cap each epoch to 2000 iterations for faster cycles
limit_val_batches: 200     # Limit validation to 200 batches to avoid long validation

# KITTI-360 Dataset with Adaptive Sampling
data:
  train:
    _target_: data.dynamic_dataloader.DynamicTorchDataset
    num_workers: ${num_workers}
    max_img_per_gpu: ${max_img_per_gpu}
    shuffle: True
    pin_memory: True
    common_config:
      img_size: ${img_size}
      patch_size: ${patch_size}
      debug: False
      repeat_batch: False
      training: True
      inside_random: True
      rescale: True
      rescale_aug: True
      landscape_check: False
      load_depth: True
      get_nearby: False
      load_track: False
      track_num: 256
      fix_img_num: -1
      fix_aspect_ratio: 1.0
      allow_duplicate_img: False
      img_nums: [8, 8]  # Fixed sequence length for KITTI-360
      augs:
        scales: null  # No scale augmentation for now
        aspects: [1.0, 1.0]  # Fixed aspect ratio
        cojitter: False
        cojitter_ratio: 0.3
        color_jitter: null
        gray_scale: False
        gau_blur: False
    persistent_workers: True
    prefetch_factor: 8
    dataset:
      _target_: data.composed_dataset.ComposedDataset
      dataset_configs:
        - _target_: data.datasets.kitti360.KITTI360Dataset
          root_dir: /home/zerun/data/dataset/KITTI-360
          split: train
          camera_id: 0  # Left camera (image_00)
          # Adaptive sampling configuration
          sampling_strategy: adaptive  # 'adaptive' or 'uniform'
          building_sampling_weights: [0.5, 0.3, 0.2]  # [rich, mixed, road]
          # LiDAR accumulation configuration
          accumulation_frames: 4  # Â±2 frames accumulation
          min_valid_points: 2000  # Minimum depth points per frame
          # Semantic weighting configuration
          semantic_weight_enabled: True
          filter_buildings_only: False  # Don't hard filter, use soft weighting
          # Depth range
          depth_range: [0.1, 80.0]  # LiDAR effective range in meters
          # Dataset length
          len_train: 50000
          len_test: 5000

  val:
    _target_: data.dynamic_dataloader.DynamicTorchDataset
    num_workers: ${num_workers}
    max_img_per_gpu: ${max_img_per_gpu}
    shuffle: False
    pin_memory: True
    common_config:
      img_size: ${img_size}
      patch_size: ${patch_size}
      debug: False
      repeat_batch: False
      training: False
      inside_random: False
      rescale: True
      rescale_aug: False
      landscape_check: False
      load_depth: True
      get_nearby: False
      load_track: False
      track_num: 256
      fix_img_num: -1
      fix_aspect_ratio: 1.0
      allow_duplicate_img: False
      img_nums: [8, 8]  # Fixed sequence length for KITTI-360
      augs:
        scales: null
        aspects: [1.0, 1.0]
        cojitter: False
        cojitter_ratio: 0.5
        color_jitter: null
        gray_scale: False
        gau_blur: False
    persistent_workers: True
    prefetch_factor: 8
    dataset:
      _target_: data.composed_dataset.ComposedDataset
      dataset_configs:
        - _target_: data.datasets.kitti360.KITTI360Dataset
          root_dir: /home/zerun/data/dataset/KITTI-360
          split: val
          camera_id: 0
          sampling_strategy: uniform  # Uniform sampling for validation
          accumulation_frames: 4
          min_valid_points: 5000  # INCREASED from 2000 to filter sparse frames
          semantic_weight_enabled: False  # Disable for validation
          filter_buildings_only: False
          depth_range: [0.1, 80.0]
          len_train: 50000
          len_test: 2000  # REDUCED to use fewer but higher quality validation samples

logging:
  log_dir: logs/${exp_name}
  log_visuals: True
  log_freq: 10
  log_level_primary: INFO
  log_level_secondary: WARNING
  all_ranks: False
  tensorboard_writer:
    _target_: train_utils.tb_writer.TensorBoardLogger
    path: ${logging.log_dir}/tensorboard
  scalar_keys_to_log:
    train:
      keys_to_log:
        - loss_objective
        - loss_camera
        - loss_T
        - loss_R
        - loss_FL
        - loss_conf_depth
        - loss_reg_depth
        - loss_grad_depth
    val:
      keys_to_log:
        - loss_objective
        - loss_camera
        - loss_T
        - loss_R
        - loss_FL
        - loss_conf_depth
        - loss_reg_depth
        - loss_grad_depth
  log_visual_frequency:
    train: 100
    val: 50
  visuals_keys_to_log:
    train:
      keys_to_log:
        - images
        - depth
      modality: video
    val:
      keys_to_log:
        - images
        - depth
      modality: video
  visuals_per_batch_to_log: 8
  video_logging_fps: 2

checkpoint:
  save_dir: logs/${exp_name}/ckpts
  save_freq: 2
  resume_checkpoint_path: ./pretrained/vggt-1b/model.pt  # Update this path!
  strict: False
  enabled: true

# Loss weights - emphasize depth for building facades
loss:
  _target_: loss.MultitaskLoss
  camera:
    weight: 2.0              # Moderate camera loss (still important)
    loss_type: "l1"
  depth:
    weight: 5.0              # Strong depth loss (main focus)
    gradient_loss_fn: "grad"  # Gradient loss for smooth facades
    valid_range: 0.99        # Strict outlier filtering
    # Semantic weighting and curriculum learning
    use_semantic_weighting: True  # Enable semantic pixel weighting
    facade_boost_ratio: 0.4  # Boost facade weights in first 40% of epochs
  point: null                # Disable point loss
  track: null                # Disable track loss

optim:
  param_group_modifiers: False

  optimizer:
    _target_: torch.optim.AdamW
    lr: 1e-4                 # Higher LR for LoRA (10x full finetuning)
    weight_decay: 0.01       # Lower weight decay for LoRA

  frozen_module_names:
    - "*aggregator*"         # Freeze aggregator completely
    - "*camera_head*"        # Freeze camera head

  amp:
    enabled: True
    amp_dtype: bfloat16      # Use bfloat16 for RTX 5090

  gradient_clip:
    _target_: train_utils.gradient_clip.GradientClipper
    configs:
      - module_name: ["depth_head"]
        max_norm: 1.0
        norm_type: 2

  options:
    lr:
      - scheduler:
          _target_: fvcore.common.param_scheduler.CompositeParamScheduler
          schedulers:
            - _target_: fvcore.common.param_scheduler.LinearParamScheduler
              start_value: 1e-6
              end_value: 1e-4
            - _target_: fvcore.common.param_scheduler.CosineParamScheduler
              start_value: 1e-4
              end_value: 1e-6
          lengths: [0.1, 0.9]  # 10% warmup, 90% cosine decay
          interval_scaling: ['rescaled', 'rescaled']
    weight_decay:
      - scheduler:
          _target_: fvcore.common.param_scheduler.ConstantParamScheduler
          value: 0.01

max_epochs: 20

model:
  _target_: vggt.models.vggt.VGGT
  enable_camera: True
  enable_depth: True
  enable_point: False
  enable_track: False

distributed:
  backend: nccl
  comms_dtype: None
  find_unused_parameters: False
  timeout_mins: 30
  gradient_as_bucket_view: True
  bucket_cap_mb: 25
  broadcast_buffers: True

cuda:
  cudnn_deterministic: False
  cudnn_benchmark: True      # Enable for performance
  allow_tf32: True
