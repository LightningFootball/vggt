# KITTI-360 建筑场景 LoRA 微调评估对比与建议（VGGT）

本文基于仓库内 evaluate 目录的评估产物，对两次 LoRA 微调进行全面对比与复盘，给出可操作的结论与后续建议。

- 训练一（记作 strategy_b）：先用 `training/config/lora_kitti360_strategy_b_15epoch.yaml` 训练 20 epoch，再改为 `training/config/lora_kitti360_strategy_b.yaml` 放松 LoRA 参数继续训练与评估。
- 训练二（记作 strategy_b_soft）：全程使用温和 LoRA 配置 `training/config/lora_kitti360_strategy_b_soft.yaml`（较低 LR、较小 α）。
- 两次均在“预测头 + Transformer 后 8 层”注入 LoRA。
- 评估与可视化来自：`scripts/evaluate_kitti360_buildings.py`、`scripts/visualize_kitti360_metrics.py`。
- 输出位置：
  - 训练一（500 序列采样）：`evaluate/lora_kitti360_strategy_b`
  - 训练二（500 序列采样）：`evaluate/lora_kitti360_strategy_b_soft`
  - 训练二（完整评估）：`evaluate/lora_kitti360_strategy_b_soft_full`

重要说明：500 序列采样与完整评估的基线统计不同，跨目录的“绝对数值”不可直接逐项对比。下文以“相对各自基线的改变量”为主，并辅以趋势图进行判断。


## 结论摘要（TL;DR）

- 建筑区域深度主指标上，训练一明显优于训练二。
  - 相对各自基线，训练一在建筑 AbsRel、RMSE、δ<1.25 均取得更大提升；训练二在 δ<1.25 的增益明显偏弱。
- 几何质量（法线/平面）方面，训练二略好于训练一，但差距不大；两者均较基线有提升。
- 位姿误差（ATE/RPE）基本不敏感，变化幅度很小；光度一致性 inlier 比例在两次训练中都有一定下降（需要关注）。
- 综合评分（脚本中定义的加权分数）：
  - 训练一最佳 checkpoint_34：0.3455（较基线 +30.9%）。
  - 训练二（500 采样）最佳 checkpoint_37：0.2999（较基线 +15.8%）。
  - 训练二（完整评估）最佳 checkpoint_45：0.2909（较基线 +14.9%）。
- 训练稳定性：训练一在 checkpoint≈20 出现“跃迁式”改进，随后稳定上升；训练二整体平滑但坡度较小，后期趋于平台。

推荐：若目标是“建筑场景深度估计能力”，优先选用训练一的 checkpoint_34（AbsRel 与 RMSE 最优）或 checkpoint_36（δ<1.25 最优附近）；若更看重几何一致性（法线/平面）与更平滑的收敛，可考虑训练二后期权重，但需接受深度准确率上的让步。


## 关键指标纵横对比

下表给出“各自 run 的基线 → 最佳 checkpoint”的改变量（来自 metrics_overall.csv 计算）：

- 训练一（strategy_b，最佳 checkpoint_34）
  - Building AbsRel: 1.7214 → 0.6107（↓64.5%）
  - Building δ<1.25: 0.4030 → 0.4375（↑8.6%）
  - Building RMSE: 16.50 → 11.02（↓33.2%）
  - Normal mean(°): 83.76 → 82.67（↓1.3%）
  - Normal inlier<30°: 0.122 → 0.158（↑28.8%）
  - Planarity inlier: 0.141 → 0.200（↑42.5%）
  - Photometric inlier: 0.650 → 0.498（↓23.3%）
  - ATE trans: 3603 → 3556（↓1.3%）

- 训练二（strategy_b_soft，500 采样，最佳 checkpoint_37）
  - Building AbsRel: 2.044 → 0.789（↓61.4%）
  - Building δ<1.25: 0.382 → 0.386（↑0.9%）
  - Building RMSE: 18.13 → 11.74（↓35.2%）
  - Normal mean(°): 83.73 → 81.19（↓3.0%）
  - Normal inlier<30°: 0.118 → 0.173（↑46.2%）
  - Planarity inlier: 0.149 → 0.229（↑53.7%）
  - Photometric inlier: 0.655 → 0.486（↓25.8%）
  - ATE trans: 3629 → 3639（↑0.3%，略差）

- 训练二（strategy_b_soft，完整评估，最佳 checkpoint_45）
  - Building AbsRel: 2.236 → 0.819（↓63.4%）
  - Building δ<1.25: 0.368 → 0.385（↑4.5%）
  - Building RMSE: 18.40 → 11.90（↓35.3%）
  - Normal mean(°): 84.08 → 81.10（↓3.5%）
  - Normal inlier<30°: 0.117 → 0.174（↑49.6%）
  - Planarity inlier: 0.149 → 0.216（↑45.1%）
  - Photometric inlier: 0.647 → 0.480（↓25.8%）
  - ATE trans: 3620.31 → 3620.25（≈持平）

解读：
- 深度主指标（AbsRel、RMSE、δ<1.25）：训练一在建筑区域的综合提升更大，尤其 δ<1.25 的提升最为稳定；训练二在 δ<1.25 上增益偏小（完整评估也仅 +4.5%），有“欠拟合”迹象。
- 几何质量：训练二在法线角度均值与 <30° 内点比例、平面内点比例上略优，说明“温和 LoRA”更偏向几何一致性与表面光滑性，但并未同步转化为 δ<1.25 的显著提升。
- 光度一致性（建筑区域重投影 inlier 比例）在两次训练中都有下降，提示 LoRA 适配后纹理一致性略受影响；若部署需要光度稳定，可考虑在训练里适度加入相关约束或后处理。
- 位姿指标整体不敏感，ATE/RPE 变化很小；LoRA 主要提升发生在深度与几何质量上。


## 趋势与稳定性（结合 plots）

- 主深度指标（01_main_depth_metrics.png）：
  - 训练一在 ckpt≈20 出现明显“跃迁”，Full 图像的 δ<1.25 接近 0.68~0.70，建筑区域 δ<1.25 也从 0.15 附近跃升到 0.35~0.44 区间，并保持稳定上行；建筑 AbsRel 随后持续下降至 ~0.61。
  - 训练二整体缓慢改善，后期平台化明显，建筑 δ<1.25 稳态约 0.38~0.39。
- 建筑 vs 非建筑（02_building_vs_nonbuilding.png）：两次训练均能在“建筑”上取得实质下降（AbsRel、RMSE、MAE），且对“非建筑”没有破坏性影响（多为小幅改进）。
- 几何质量（03_geometry_quality.png）：训练二的法线 inlier 曲线更高，平面内点比例更高、残差更低；训练一在几何上虽有提升，但相对略弱。
- 位姿（04_pose_errors.png）：两次趋势都比较平稳，未见与深度明显耦合的异常波动。
- 稳定性（06_training_stability.png）：训练一在 20 附近的 CV 峰值后迅速降至 <5% 阈值以下并长期保持；训练二全程较“平滑”，但也意味着提升速度较慢且平台期更长。
- 综合评分（07_comprehensive_score.png）：训练一的最佳提升幅度约 +30.9%；训练二完整评估约 +14.9%。


## 资源与效率

- 训练一最佳 ckpt 的推理开销（策略可能与环境不同，数值仅供参考）：
  - FPS ≈ 1.12、Latency ≈ 0.90 s、VRAM ≈ 20.3 GB。
- 训练二完整评估的最佳 ckpt：
  - FPS ≈ 0.45、Latency ≈ 2.23 s、VRAM ≈ 20.3 GB。

备注：`strategy_b_soft`（500 采样）一次评估记录到 ~10 GB VRAM 与更低 FPS，推测为评估参数或环境差异所致（如是否开启 bf16、并发度、数据加载方式等）。总体上，LoRA 推理相对基线显存增幅明显（约翻倍），FPS 有较大下降。


## 可能的成因与取舍

- 训练一早期使用“更强/更激进”的 LoRA 设置，随后在约 20 epoch 附近放松参数，带来显著的性能跃迁并保持稳定提升；
- 训练二全程“温和”，提升更平滑也更保守：几何一致性上略有收益，但难以把 δ<1.25 推到更高（更接近部署侧可接受误差）。
- 光度 inlier 比例下降提示：模型在纹理一致性/投影对齐方面可能被牺牲，需要在训练目标中重新平衡（例如引入光度/一致性损失或数据增强策略）。


## 实操建议

- 模型选择（当前阶段）
  - 深度主指标优先：选用训练一 `checkpoint_34`（AbsRel/RMSE 最优）或 `checkpoint_36`（δ<1.25 更高）作为建筑领域的候选权重。
  - 几何一致性优先：可评估训练二后期权重（如 `checkpoint_45`），但需接受 δ<1.25 的折衷。

- 下一步微调策略（建议小步修正，而非重启大改）
  1) 以训练一 `checkpoint_34/36` 为起点，降低 LR（例如 1/3~1/5）、缩小 α，进行 3~5 epoch 的“温和收敛”。
  2) 逐步冻结部分 LoRA 分支（如仅保留注意力 Q/K，冻结 V/Proj），在保留已获改进的同时，稳住法线与光度一致性指标。
  3) 在损失上适度提高“建筑区域”采样权重与几何一致性项（法线/平面）权重，但设上限，避免压制 δ<1.25 的提升。
  4) 注入位置试验：仍以“后 8 层”为主，可对更靠后的 10~12 层做小规模探索，或仅对注意力层注入以减少参数与显存占用。

- 评估与选择策略
  - 对训练一再做一次“完整评估”（与 `strategy_b_soft_full` 对齐），避免采样差异导致的比较偏差。
  - 在可部署约束下做“质量-代价”权衡：选取综合分数高、FPS/VRAM 满足上线需求的 checkpoint，而非单一指标最优。
  - 评估时可启用 `--bf16`、`--parallel-models` 来加速；如使用 `--max-seqs`，建议加上 `--stratified-sampling` 并固定随机种子，保证可比性。


## 对评估脚本与可视化的改进建议

为增强可比性、可复现与可解释性，建议在 `scripts/evaluate_kitti360_buildings.py` / `scripts/visualize_kitti360_metrics.py` 中加入：

- 元数据与可复现
  - 在输出目录写入 `metadata.json`：记录数据 split、对齐方式（align）、是否 stratified、随机种子、序列/帧清单、采样比例、显存/设备信息。
  - 对 `--max-seqs` 的采样固定随机种子，并将选中序列列表保存，便于跨 run 复现与公平对比。
- 指标完善
  - 在 CSV 中新增“样本计数”（全局/建筑/非建筑的有效像素或帧数）与“评估时长”。
  - 增加对齐方式消融（`none/scale/median/scale_shift`）的小表格或多曲线对比。
  - 输出 Photometric 阈值-曲线（inlier ratio vs threshold），而非单点；并标注在 radar/comprehensive 计算中所用的阈值。
  - 增加“质量-代价”的 Pareto 前沿图（AbsRel、δ<1.25、Planarity vs FPS/VRAM）。
  - 给出 Top‑K checkpoint 排行（包含关键指标与综合分）。
- 可视化补充
  - 建筑区域误差分布（直方/箱线）与法线误差热力图示例帧；
  - 分场景/材质（如玻璃幕墙、砖墙、遮挡）的小类对比（若有标注/可近似）。


## 最终结论

- 训练一（strategy_b）在“建筑区域深度估计”上总体优势更为明显：AbsRel/RMSE/δ<1.25 的增益更大，且训练在 ckpt≈20 后快速进入稳定、持续提升期。
- 训练二（strategy_b_soft）更温和，几何一致性略优，但无法将建筑 δ<1.25 推到与训练一相当的水平；若优先级是几何平滑，可考虑选用其后期权重。
- 建议以训练一 `checkpoint_34/36` 为当前主线，再做 3~5 个 epoch 的“温和精修”，同时在损失与采样上引入适度的几何/光度一致性约束，以兼顾深度精度与几何质量；完成后对两个候选在完整评估集上复核，结合 FPS/VRAM 做最终选择。

