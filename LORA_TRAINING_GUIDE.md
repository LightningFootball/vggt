# LoRA Fine-tuning Guide for VGGT on ETH3D Building Facades

æœ¬æŒ‡å—è¯¦ç»†è¯´æ˜å¦‚ä½•ä½¿ç”¨LoRAåœ¨ETH3Då»ºç­‘å¤–ç«‹é¢æ•°æ®é›†ä¸Šå¾®è°ƒVGGTæ¨¡å‹ã€‚

## ğŸ“‹ ç›®å½•

- [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
- [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
- [è®­ç»ƒç­–ç•¥](#è®­ç»ƒç­–ç•¥)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [è®­ç»ƒç›‘æ§](#è®­ç»ƒç›‘æ§)
- [è¯„ä¼°ä¸åˆ†æ](#è¯„ä¼°ä¸åˆ†æ)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ”§ ç¯å¢ƒå‡†å¤‡

### 1. å®‰è£…ä¾èµ–

```bash
# åŸºç¡€ä¾èµ–ï¼ˆå·²å®‰è£…ï¼‰
pip install -r requirements.txt

# è®­ç»ƒä¾èµ–
pip install -r requirements_training.txt

# ç¡®è®¤PEFTåº“å·²å®‰è£…
pip install peft>=0.7.0
```

### 2. ç¡¬ä»¶è¦æ±‚

- **GPU**: NVIDIA RTX 5090 (32GB VRAM) âœ“
- **CUDA**: æ”¯æŒbfloat16ï¼ˆCompute Capability >= 8.0ï¼‰âœ“
- **ç³»ç»Ÿ**: Linux (æ¨è)

**å…³äºBF16**ï¼š
- âœ… VGGTåŸé¡¹ç›®å®Œå…¨æ”¯æŒbfloat16ï¼ˆè§`training/config/default.yaml:127`ï¼‰
- âœ… RTX 5090æ”¯æŒåŸç”ŸBF16ç¡¬ä»¶åŠ é€Ÿ
- âœ… æ‰€æœ‰é…ç½®æ–‡ä»¶å·²å¯ç”¨`amp_dtype: bfloat16`
- ç›¸æ¯”FP32ï¼ŒBF16å¯èŠ‚çº¦çº¦50%æ˜¾å­˜ï¼Œæå‡1.5-2å€è®­ç»ƒé€Ÿåº¦

---

## ğŸ“¦ æ•°æ®å‡†å¤‡

### 1. ETH3Dæ•°æ®é›†

ä½ å·²ç»ä¸‹è½½çš„æ•°æ®ï¼š
```
/home/zerun/data/dataset/ETH3D/Stereo/High-res_multi-view/
â”œâ”€â”€ multi_view_training_dslr_undistorted/     # ä¸»å›¾åƒæ•°æ® âœ“
â”œâ”€â”€ multi_view_training_dslr_occlusion/       # é®æŒ¡æ©è†œ âœ“
â””â”€â”€ multi_view_training_dslr_scan_eval/       # Ground Truth âœ“
```

### 2. é¢„è®­ç»ƒæ¨¡å‹

ä¸‹è½½VGGTé¢„è®­ç»ƒæ¨¡å‹ï¼š

```bash
# é€‰é¡¹1: éå•†ä¸šç‰ˆæœ¬
huggingface-cli download facebook/VGGT-1B --local-dir ./pretrained/vggt-1b

# é€‰é¡¹2: å•†ä¸šç‰ˆæœ¬
huggingface-cli download facebook/VGGT-1B-Commercial --local-dir ./pretrained/vggt-1b-commercial
```

### 3. æ›´æ–°é…ç½®æ–‡ä»¶

ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„checkpointè·¯å¾„ï¼š

```bash
# ç¼–è¾‘é…ç½®æ–‡ä»¶
nano training/config/lora_eth3d_strategy_a.yaml

# æ‰¾åˆ°è¿™ä¸€è¡Œå¹¶æ›´æ–°ï¼š
resume_checkpoint_path: /path/to/your/pretrained/checkpoint.pt
```

ä¾‹å¦‚ï¼š
```yaml
resume_checkpoint_path: ./pretrained/vggt-1b/model.pt
```

---

## ğŸ¯ è®­ç»ƒç­–ç•¥

æˆ‘ä»¬æä¾›ä¸‰ç§æ¸è¿›å¼è®­ç»ƒç­–ç•¥ï¼š

### ç­–ç•¥A: Depth Head Onlyï¼ˆæ¨èèµ·ç‚¹ï¼‰

**ç‰¹ç‚¹ï¼š**
- âœ… æœ€å¿«è®­ç»ƒé€Ÿåº¦
- âœ… æœ€å°‘æ˜¾å­˜å ç”¨ï¼ˆ~10GBï¼‰
- âœ… é€‚åˆéªŒè¯pipeline
- âš ï¸ æ€§èƒ½æå‡æœ‰é™

**é…ç½®ï¼š** `lora_eth3d_strategy_a.yaml`

**LoRAå‚æ•°ï¼š**
- Rank: 16
- Target: Depth Head only
- Trainable params: ~8M (0.8%)

### ç­–ç•¥B: AggregatoråæœŸå±‚ + Depth Headï¼ˆæ¨èæœ€ä¼˜ï¼‰

**ç‰¹ç‚¹ï¼š**
- âœ… å¹³è¡¡æ€§èƒ½ä¸æ•ˆç‡
- âœ… é’ˆå¯¹æ€§å­¦ä¹ å»ºç­‘ç‰¹å¾
- âœ… æ˜¾å­˜å ç”¨é€‚ä¸­ï¼ˆ~18GBï¼‰
- âœ… **æœ€æ¨èç”¨äºç”Ÿäº§**

**é…ç½®ï¼š** `lora_eth3d_strategy_b.yaml`

**LoRAå‚æ•°ï¼š**
- Rank: 16
- Target: Aggregator layers 12-23 + Depth Head
- Trainable params: ~45M (4.5%)

### ç­–ç•¥C: Full LoRAï¼ˆæœ€å¤§å®¹é‡ï¼‰

**ç‰¹ç‚¹ï¼š**
- âœ… æœ€å¼ºå­¦ä¹ èƒ½åŠ›
- âš ï¸ æœ€æ…¢è®­ç»ƒé€Ÿåº¦
- âš ï¸ æ˜¾å­˜å ç”¨æœ€é«˜ï¼ˆ~28GBï¼‰
- âš ï¸ å¯èƒ½è¿‡æ‹Ÿåˆ

**é…ç½®ï¼š** `lora_eth3d_strategy_c.yaml`

**LoRAå‚æ•°ï¼š**
- Rank: 16
- Target: All Aggregator + Depth Head + Camera Head
- Trainable params: ~90M (9%)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³•1: ä½¿ç”¨Shellè„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# ç»™è„šæœ¬æ·»åŠ æ‰§è¡Œæƒé™
chmod +x scripts/train_lora_eth3d.sh

# è®­ç»ƒç­–ç•¥Aï¼ˆæµ‹è¯•pipelineï¼‰
bash scripts/train_lora_eth3d.sh strategy_a

# è®­ç»ƒç­–ç•¥Bï¼ˆç”Ÿäº§ä½¿ç”¨ï¼‰
bash scripts/train_lora_eth3d.sh strategy_b

# è®­ç»ƒç­–ç•¥Cï¼ˆæœ€å¤§æ€§èƒ½ï¼‰
bash scripts/train_lora_eth3d.sh strategy_c
```

### æ–¹æ³•2: ç›´æ¥ä½¿ç”¨torchrunï¼ˆæ¨èï¼‰

```bash
# ç­–ç•¥A
torchrun --nproc_per_node=1 training/launch.py --config lora_eth3d_strategy_a

# ç­–ç•¥B
torchrun --nproc_per_node=1 training/launch.py --config lora_eth3d_strategy_b

# ç­–ç•¥C
torchrun --nproc_per_node=1 training/launch.py --config lora_eth3d_strategy_c
```

**é‡è¦**ï¼šå³ä½¿æ˜¯å•GPUè®­ç»ƒï¼Œä¹Ÿå¿…é¡»ä½¿ç”¨`torchrun`å¯åŠ¨å™¨ï¼Œå› ä¸ºè®­ç»ƒä»£ç éœ€è¦åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡ï¼ˆ`LOCAL_RANK`ã€`RANK`ï¼‰ã€‚

### è®­ç»ƒå‚æ•°è¯´æ˜

é…ç½®æ–‡ä»¶ä¸­çš„å…³é”®å‚æ•°ï¼š

```yaml
# è®­ç»ƒåŸºç¡€å‚æ•°
max_epochs: 20                 # è®­ç»ƒè½®æ•°
max_img_per_gpu: 4             # æ¯GPUå›¾åƒæ•°ï¼ˆè°ƒæ•´ä»¥é€‚åº”æ˜¾å­˜ï¼‰
accum_steps: 1                 # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°

# LoRAå‚æ•°
lora:
  rank: 16                     # LoRAç§©ï¼ˆè¶Šå¤§å®¹é‡è¶Šå¤§ï¼Œæ˜¾å­˜è¶Šå¤šï¼‰
  alpha: 32                    # ç¼©æ”¾å› å­ï¼ˆalpha/rank=2.0ï¼‰
  dropout: 0.1                 # Dropoutç‡

# ä¼˜åŒ–å™¨
optimizer:
  lr: 1e-4                     # å­¦ä¹ ç‡ï¼ˆLoRAé€šå¸¸éœ€è¦æ›´é«˜LRï¼‰
  weight_decay: 0.01           # æƒé‡è¡°å‡

# æŸå¤±æƒé‡
loss:
  camera:
    weight: 2.0                # ç›¸æœºæŸå¤±æƒé‡
  depth:
    weight: 5.0                # æ·±åº¦æŸå¤±æƒé‡ï¼ˆä¸»è¦ä¼˜åŒ–ç›®æ ‡ï¼‰
```

---

## ğŸ“Š è®­ç»ƒç›‘æ§

### 1. TensorBoard

å¯åŠ¨TensorBoardç›‘æ§ï¼š

```bash
# ç­–ç•¥A
tensorboard --logdir logs/lora_eth3d_strategy_a_r16/tensorboard

# ç­–ç•¥B
tensorboard --logdir logs/lora_eth3d_strategy_b_r16/tensorboard

# ç­–ç•¥C
tensorboard --logdir logs/lora_eth3d_strategy_c_r16/tensorboard
```

è®¿é—® `http://localhost:6006`

### 2. ç›‘æ§æŒ‡æ ‡

**å…³é”®æŸå¤±ï¼š**
- `loss_objective`: æ€»æŸå¤±ï¼ˆåº”è¯¥ç¨³å®šä¸‹é™ï¼‰
- `loss_conf_depth`: æ·±åº¦ç½®ä¿¡æŸå¤±ï¼ˆä¸»è¦ä¼˜åŒ–ç›®æ ‡ï¼‰
- `loss_reg_depth`: æ·±åº¦å›å½’æŸå¤±
- `loss_grad_depth`: æ·±åº¦æ¢¯åº¦æŸå¤±ï¼ˆå¹³æ»‘æ€§ï¼‰

**å­¦ä¹ ç‡è°ƒåº¦ï¼š**
- å‰10% warmup: 1e-6 â†’ 1e-4
- å90% cosine decay: 1e-4 â†’ 1e-6

### 3. æ£€æŸ¥ç‚¹

æ£€æŸ¥ç‚¹è‡ªåŠ¨ä¿å­˜åœ¨ï¼š
```
logs/{exp_name}/ckpts/
â”œâ”€â”€ checkpoint.pth              # æœ€æ–°æ£€æŸ¥ç‚¹
â”œâ”€â”€ checkpoint_2.pth            # ç¬¬2ä¸ªepoch
â”œâ”€â”€ checkpoint_4.pth            # ç¬¬4ä¸ªepoch
â””â”€â”€ ...
```

---

## ğŸ¯ è¯„ä¼°ä¸åˆ†æ

### 1. è¿è¡Œè¯„ä¼°

```bash
# è¯„ä¼°ç­–ç•¥A
python scripts/evaluate_eth3d.py \
    --checkpoint logs/lora_eth3d_strategy_a_r16/ckpts/checkpoint.pth \
    --config lora_eth3d_strategy_a \
    --save-vis

# è¯„ä¼°ç­–ç•¥B
python scripts/evaluate_eth3d.py \
    --checkpoint logs/lora_eth3d_strategy_b_r16/ckpts/checkpoint.pth \
    --config lora_eth3d_strategy_b \
    --save-vis
```

### 2. è¯„ä¼°æŒ‡æ ‡

è¾“å‡ºç¤ºä¾‹ï¼š
```
Depth Metrics:
  MAE:       0.1234 Â± 0.0456 (median: 0.1123)
  RMSE:      0.2345 Â± 0.0789
  Abs Rel:   0.0567 Â± 0.0123
  Sq Rel:    0.0234 Â± 0.0089

Threshold Accuracy:
  Î´ < 1.25:  0.9234
  Î´ < 1.25Â²: 0.9789
  Î´ < 1.25Â³: 0.9912
```

**æŒ‡æ ‡è¯´æ˜ï¼š**
- **MAE**: å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
- **RMSE**: å‡æ–¹æ ¹è¯¯å·®ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
- **Î´ < 1.25**: é˜ˆå€¼å‡†ç¡®åº¦ï¼ˆè¶Šå¤§è¶Šå¥½ï¼Œ>0.9ä¸ºä¼˜ç§€ï¼‰

### 3. å¯è§†åŒ–ç»“æœ

å¯è§†åŒ–ä¿å­˜åœ¨ `eval_results/visualizations/`ï¼š
- è¾“å…¥å›¾åƒ
- é¢„æµ‹æ·±åº¦å›¾
- Ground truthæ·±åº¦å›¾
- è¯¯å·®çƒ­åŠ›å›¾

---

## ğŸ”¬ å®éªŒæµç¨‹å»ºè®®

### ç¬¬1é˜¶æ®µï¼šPipelineéªŒè¯ï¼ˆ1-2å¤©ï¼‰

```bash
# 1. è®­ç»ƒç­–ç•¥Aæµ‹è¯•2ä¸ªepoch
python training/launch.py --config lora_eth3d_strategy_a \
    max_epochs=2

# 2. æ£€æŸ¥æ˜¯å¦æ­£å¸¸è¿è¡Œ
# - æŸ¥çœ‹TensorBoardæŸå¤±æ›²çº¿
# - ç¡®è®¤æ²¡æœ‰OOMé”™è¯¯
# - éªŒè¯checkpointä¿å­˜æˆåŠŸ
```

### ç¬¬2é˜¶æ®µï¼šè¶…å‚æ•°è°ƒä¼˜ï¼ˆ3-5å¤©ï¼‰

**LoRA Rankæ‰«æï¼š**
```bash
# å°è¯•ä¸åŒrankå€¼
# ç¼–è¾‘é…ç½®æ–‡ä»¶ä¿®æ”¹lora.rank: [8, 16, 32, 64]

# Rank 8
sed -i 's/rank: 16/rank: 8/g' training/config/lora_eth3d_strategy_b.yaml
python training/launch.py --config lora_eth3d_strategy_b

# Rank 32
sed -i 's/rank: 8/rank: 32/g' training/config/lora_eth3d_strategy_b.yaml
python training/launch.py --config lora_eth3d_strategy_b
```

**å­¦ä¹ ç‡æ‰«æï¼š**
```bash
# å°è¯•ä¸åŒå­¦ä¹ ç‡: [5e-5, 1e-4, 2e-4, 5e-4]
# ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„optimizer.lrå€¼
```

### ç¬¬3é˜¶æ®µï¼šå®Œæ•´è®­ç»ƒï¼ˆ1å‘¨ï¼‰

```bash
# ä½¿ç”¨æœ€ä¼˜è¶…å‚æ•°è®­ç»ƒç­–ç•¥B
python training/launch.py --config lora_eth3d_strategy_b \
    max_epochs=20

# è¯„ä¼°
python scripts/evaluate_eth3d.py \
    --checkpoint logs/lora_eth3d_strategy_b_r16/ckpts/checkpoint_20.pth \
    --save-vis
```

### ç¬¬4é˜¶æ®µï¼šå¯¹æ¯”å®éªŒ

å¯¹æ¯”ä¸‰ç§ç­–ç•¥çš„æ€§èƒ½ï¼š
1. è®­ç»ƒé€Ÿåº¦
2. æ·±åº¦ä¼°è®¡ç²¾åº¦
3. çª—æˆ·åŒºåŸŸä¸“é¡¹è¯„ä¼°
4. æ³›åŒ–èƒ½åŠ›æµ‹è¯•

---

## â“ å¸¸è§é—®é¢˜

### Q1: OOMé”™è¯¯ï¼ˆæ˜¾å­˜ä¸è¶³ï¼‰

**è§£å†³æ–¹æ¡ˆï¼š**
```yaml
# å‡å°batch size
max_img_per_gpu: 2  # ä»4é™åˆ°2

# å¯ç”¨æ¢¯åº¦ç´¯ç§¯
accum_steps: 2      # ä»1å¢åŠ åˆ°2

# å‡å°å›¾åƒåˆ†è¾¨ç‡
img_size: 420       # ä»518é™åˆ°420

# ä½¿ç”¨æ›´å°çš„LoRA rank
lora:
  rank: 8           # ä»16é™åˆ°8
```

### Q2: è®­ç»ƒä¸æ”¶æ•›

**æ£€æŸ¥æ¸…å•ï¼š**
1. å­¦ä¹ ç‡æ˜¯å¦è¿‡é«˜/è¿‡ä½ï¼Ÿ
   - æ¨èèŒƒå›´ï¼š5e-5 to 2e-4
2. æ˜¯å¦åŠ è½½äº†é¢„è®­ç»ƒæƒé‡ï¼Ÿ
   - æ£€æŸ¥`resume_checkpoint_path`
3. æŸå¤±æƒé‡æ˜¯å¦åˆç†ï¼Ÿ
   - depth.weightå»ºè®®2-5ä¹‹é—´

### Q3: éªŒè¯é›†æ€§èƒ½ä¸æå‡

**å¯èƒ½åŸå› ï¼š**
1. **è¿‡æ‹Ÿåˆ**ï¼šè®­ç»ƒé›†lossä¸‹é™ä½†éªŒè¯é›†ä¸é™
   - å¢åŠ dropout: `lora.dropout: 0.2`
   - å‡å°rank: `lora.rank: 8`
   - æ·»åŠ æ•°æ®å¢å¼º

2. **å­¦ä¹ ç‡è¿‡é«˜**ï¼šéªŒè¯é›†losséœ‡è¡
   - é™ä½å­¦ä¹ ç‡ï¼š`lr: 5e-5`

3. **Epochä¸è¶³**ï¼šè¿˜æœªæ”¶æ•›
   - å¢åŠ è®­ç»ƒè½®æ•°ï¼š`max_epochs: 30`

### Q4: PEFTå¯¼å…¥é”™è¯¯

```bash
# å®‰è£…PEFT
pip install peft>=0.7.0

# å¦‚æœè¿˜æœ‰é—®é¢˜ï¼Œå°è¯•ä»æºç å®‰è£…
pip install git+https://github.com/huggingface/peft.git
```

### Q5: æŠ¥é”™ "int() argument must be a string... not 'NoneType'"

**é—®é¢˜**ï¼šç›´æ¥è¿è¡Œ`python training/launch.py`ä¼šæŠ¥é”™ï¼Œå› ä¸ºç¼ºå°‘åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# âŒ é”™è¯¯ï¼šç›´æ¥ç”¨ python è¿è¡Œ
python training/launch.py --config lora_eth3d_strategy_b

# âœ… æ­£ç¡®ï¼šä½¿ç”¨ torchrunï¼ˆå³ä½¿å•GPUï¼‰
torchrun --nproc_per_node=1 training/launch.py --config lora_eth3d_strategy_b

# æˆ–ä½¿ç”¨æä¾›çš„è„šæœ¬
bash scripts/train_lora_eth3d.sh strategy_b
```

### Q6: å¦‚ä½•æ¢å¤ä¸­æ–­çš„è®­ç»ƒï¼Ÿ

è®­ç»ƒä¼šè‡ªåŠ¨ä»æœ€æ–°checkpointæ¢å¤ï¼š
```bash
# åªéœ€é‡æ–°è¿è¡Œç›¸åŒå‘½ä»¤
torchrun --nproc_per_node=1 training/launch.py --config lora_eth3d_strategy_b

# æˆ–æŒ‡å®šç‰¹å®šcheckpoint
torchrun --nproc_per_node=1 training/launch.py --config lora_eth3d_strategy_b \
    checkpoint.resume_checkpoint_path=logs/lora_eth3d_strategy_b_r16/ckpts/checkpoint_10.pth
```

### Q7: å¦‚ä½•è°ƒæ•´è®­ç»ƒ/éªŒè¯é›†åˆ’åˆ†ï¼Ÿ

ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼š
```yaml
data:
  train:
    dataset:
      train_val_split: 0.85  # 85%è®­ç»ƒï¼Œ15%éªŒè¯
```

### Q8: åªæƒ³è®­ç»ƒç‰¹å®šåœºæ™¯æ€ä¹ˆåŠï¼Ÿ

ä¿®æ”¹ETH3Dæ•°æ®é›†åˆå§‹åŒ–ï¼š
```python
# åœ¨ training/data/datasets/eth3d.py ä¸­
# ä¿®æ”¹ BUILDING_SCENES åˆ—è¡¨
BUILDING_SCENES = ['facade', 'terrace']  # åªä½¿ç”¨è¿™ä¸¤ä¸ªåœºæ™¯
```

æˆ–åœ¨é…ç½®ä¸­æŒ‡å®šï¼š
```yaml
data:
  train:
    dataset:
      scenes: ['facade', 'terrace', 'electro']  # è‡ªå®šä¹‰åœºæ™¯åˆ—è¡¨
      use_building_scenes_only: False
```

---

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

### è®­ç»ƒæ—¶é—´ä¼°è®¡ï¼ˆRTX 5090ï¼‰

| ç­–ç•¥ | Epochè€—æ—¶ | 20 Epochsæ€»æ—¶é•¿ | å³°å€¼æ˜¾å­˜ |
|------|-----------|----------------|---------|
| A    | ~15åˆ†é’Ÿ   | ~5å°æ—¶         | ~12GB   |
| B    | ~30åˆ†é’Ÿ   | ~10å°æ—¶        | ~20GB   |
| C    | ~45åˆ†é’Ÿ   | ~15å°æ—¶        | ~28GB   |

### æ€§èƒ½æå‡é¢„æœŸ

ç›¸æ¯”é¢„è®­ç»ƒæ¨¡å‹åœ¨ETH3Då»ºç­‘åœºæ™¯ä¸Šï¼š
- **ç­–ç•¥A**: æ·±åº¦MAEé™ä½ 10-15%
- **ç­–ç•¥B**: æ·±åº¦MAEé™ä½ 20-30% â­æ¨è
- **ç­–ç•¥C**: æ·±åº¦MAEé™ä½ 25-35%ï¼ˆå¯èƒ½è¿‡æ‹Ÿåˆï¼‰

çª—æˆ·åŒºåŸŸä¸“é¡¹æ”¹å–„ï¼š
- çª—æ¡†æ·±åº¦ä¼°è®¡æ›´å‡†ç¡®
- ç»ç’ƒåå°„åŒºåŸŸç½®ä¿¡åº¦å»ºæ¨¡æ›´å¥½
- å¹³é¢å¢™é¢æ›´å¹³æ»‘

---

## ğŸ“ è¿›é˜¶æŠ€å·§

### 1. çª—æˆ·åŒºåŸŸä¸“é¡¹ä¼˜åŒ–

å¦‚æœä½ æœ‰çª—æˆ·åŒºåŸŸçš„åˆ†å‰²æ©è†œï¼Œå¯ä»¥å¢åŠ çª—æˆ·åŒºåŸŸçš„æŸå¤±æƒé‡ï¼š

```python
# åœ¨loss.pyçš„regression_losså‡½æ•°ä¸­
# æ ¹æ®window_maskåŠ æƒ
if window_mask is not None:
    loss_conf = loss_conf * (1 + window_mask * window_weight)
```

### 2. æ··åˆç²¾åº¦è®­ç»ƒ

å·²é»˜è®¤å¯ç”¨bfloat16ï¼š
```yaml
amp:
  enabled: True
  amp_dtype: bfloat16  # RTX 5090æ”¯æŒ
```

### 3. ä¿å­˜LoRA Adapter

ä»…ä¿å­˜LoRAæƒé‡ï¼ˆè€Œéæ•´ä¸ªæ¨¡å‹ï¼‰ï¼š
```python
from training.lora_utils import save_lora_checkpoint

save_lora_checkpoint(
    model,
    save_path='./lora_adapters/facade_adapter'
)
```

### 4. åˆå¹¶LoRAæƒé‡ç”¨äºæ¨ç†

```python
from training.lora_utils import merge_lora_weights

merged_model = merge_lora_weights(peft_model)
# merged_modelç°åœ¨æ˜¯æ™®é€šnn.Moduleï¼Œå¯ä»¥æ­£å¸¸ä¿å­˜å’Œæ¨ç†
```

---

## ğŸ“ è®¸å¯è¯

- **ä»£ç **: MIT License
- **é¢„è®­ç»ƒæ¨¡å‹**:
  - `facebook/VGGT-1B`: éå•†ä¸šä½¿ç”¨
  - `facebook/VGGT-1B-Commercial`: å•†ä¸šä½¿ç”¨ï¼ˆä¸åŒ…æ‹¬å†›äº‹ï¼‰
- **ETH3Dæ•°æ®é›†**: ä»…ç”¨äºç ”ç©¶

---

## ğŸ¤ è´¡çŒ®ä¸åé¦ˆ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·ï¼š
1. æ£€æŸ¥æœ¬æŒ‡å—çš„[å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)éƒ¨åˆ†
2. æŸ¥çœ‹TensorBoardæ—¥å¿—å’Œè®­ç»ƒè¾“å‡º
3. åœ¨é¡¹ç›®Issueä¸­æé—®

ç¥è®­ç»ƒé¡ºåˆ©ï¼ ğŸš€
